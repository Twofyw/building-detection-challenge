{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import rasterio\n",
    "import scipy\n",
    "import shapely.wkt\n",
    "import skimage.transform\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_TRAIN_DIR = \"data/train\"\n",
    "WORKING_DIR = \"data/working\"\n",
    "IMAGE_DIR = \"data/working/images/full_rgb/\"\n",
    "\n",
    "# Input files\n",
    "FMT_TRAIN_SUMMARY_PATH = str(\n",
    "    Path(BASE_TRAIN_DIR) /\n",
    "    Path(\"{prefix:s}_Train/\") /\n",
    "    Path(\"summaryData/{prefix:s}_Train_Building_Solutions.csv\"))\n",
    "FMT_TRAIN_RGB_IMAGE_PATH = str(\n",
    "    Path(\"{datapath:s}/\") /\n",
    "    Path(\"RGB-PanSharpen/RGB-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TEST_RGB_IMAGE_PATH = str(\n",
    "    Path(\"{datapath:s}/\") /\n",
    "    Path(\"RGB-PanSharpen/RGB-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TRAIN_MSPEC_IMAGE_PATH = str(\n",
    "    Path(\"{datapath:s}/\") /\n",
    "    Path(\"MUL-PanSharpen/MUL-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TEST_MSPEC_IMAGE_PATH = str(\n",
    "    Path(\"{datapath:s}/\") /\n",
    "    Path(\"MUL-PanSharpen/MUL-PanSharpen_{image_id:s}.tif\"))\n",
    "\n",
    "# Preprocessing result\n",
    "FMT_RGB_BANDCUT_TH_PATH = IMAGE_DIR + \"/rgb_bandcut{}.csv\"\n",
    "FMT_MUL_BANDCUT_TH_PATH = IMAGE_DIR + \"/mul_bandcut{}.csv\"\n",
    "\n",
    "# Image list, Image container and mask container\n",
    "FMT_VALTRAIN_IMAGELIST_PATH = IMAGE_DIR + \"/{prefix:s}_valtrain_ImageId.csv\"\n",
    "FMT_VALTRAIN_MASK_STORE = IMAGE_DIR + \"/valtrain_{}_mask.h5\"\n",
    "FMT_VALTRAIN_IM_STORE = IMAGE_DIR + \"/valtrain_{}_im.h5\"\n",
    "FMT_VALTRAIN_MUL_STORE = IMAGE_DIR + \"/valtrain_{}_mul.h5\"\n",
    "\n",
    "FMT_VALTEST_IMAGELIST_PATH = IMAGE_DIR + \"/{prefix:s}_valtest_ImageId.csv\"\n",
    "FMT_VALTEST_MASK_STORE = IMAGE_DIR + \"/valtest_{}_mask.h5\"\n",
    "FMT_VALTEST_IM_STORE = IMAGE_DIR + \"/valtest_{}_im.h5\"\n",
    "FMT_VALTEST_MUL_STORE = IMAGE_DIR + \"/valtest_{}_mul.h5\"\n",
    "\n",
    "FMT_IMMEAN = IMAGE_DIR + \"/{}_immean.h5\"\n",
    "FMT_MULMEAN = IMAGE_DIR + \"/{}_mulmean.h5\"\n",
    "\n",
    "FMT_TEST_IMAGELIST_PATH = IMAGE_DIR + \"/{prefix:s}_test_ImageId.csv\"\n",
    "FMT_TEST_IM_STORE = IMAGE_DIR + \"/test_{}_im.h5\"\n",
    "FMT_TEST_MUL_STORE = IMAGE_DIR + \"/test_{}_mul.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_name_to_area_id(datapath):\n",
    "    \"\"\"\n",
    "    Directory name to AOI number\n",
    "\n",
    "    Usage:\n",
    "\n",
    "        >>> directory_name_to_area_id(\"/data/test/AOI_2_Vegas\")\n",
    "        2\n",
    "    \"\"\"\n",
    "    dir_name = Path(datapath).name\n",
    "    if dir_name.startswith('AOI_2_Vegas'):\n",
    "        return 2\n",
    "    elif dir_name.startswith('AOI_3_Paris'):\n",
    "        return 3\n",
    "    elif dir_name.startswith('AOI_4_Shanghai'):\n",
    "        return 4\n",
    "    elif dir_name.startswith('AOI_5_Khartoum'):\n",
    "        return 5\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported city id is given.\")\n",
    "        \n",
    "def image_id_to_prefix(image_id):\n",
    "    \"\"\"\n",
    "    `AOI_3_Paris_img585` -> `AOI_3_Paris`\n",
    "    \"\"\"\n",
    "    prefix = image_id.split('img')[0][:-1]\n",
    "    return prefix\n",
    "\n",
    "\n",
    "def prefix_to_area_id(prefix):\n",
    "    area_dict = {\n",
    "        'AOI_2_Vegas': 2,\n",
    "        'AOI_3_Paris': 3,\n",
    "        'AOI_4_Shanghai': 4,\n",
    "        'AOI_5_Khartoum': 5,\n",
    "    }\n",
    "    return area_dict[area_id]\n",
    "\n",
    "\n",
    "def area_id_to_prefix(area_id):\n",
    "    area_dict = {\n",
    "        2: 'AOI_2_Vegas',\n",
    "        3: 'AOI_3_Paris',\n",
    "        4: 'AOI_4_Shanghai',\n",
    "        5: 'AOI_5_Khartoum',\n",
    "    }\n",
    "    return area_dict[area_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image_mask(area_id, is_valtrain=True):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    print(\"prep_image_mask for {}\".format(prefix))\n",
    "    if is_valtrain:\n",
    "        fn_list = FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)\n",
    "        fn_mask = FMT_VALTRAIN_MASK_STORE.format(prefix)\n",
    "    else:\n",
    "        fn_list = FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix)\n",
    "        fn_mask = FMT_VALTEST_MASK_STORE.format(prefix)\n",
    "\n",
    "    df = pd.read_csv(fn_list, index_col='ImageId')\n",
    "    df_summary = _load_train_summary_data(area_id)\n",
    "    print(\"Prepare image container: {}\".format(fn_mask))\n",
    "    \n",
    "    for image_id in tqdm.tqdm(df.index, total=len(df)):\n",
    "        im_mask = image_mask_resized_from_summary(df_summary, image_id)\n",
    "        plt.imsave(IMAGE_DIR + 'mask' + str(image_id), im_mask)\n",
    "        \n",
    "#     with tb.open_file(fn_mask, 'w') as f:\n",
    "#         for image_id in tqdm.tqdm(df.index, total=len(df)):\n",
    "#             im_mask = image_mask_resized_from_summary(df_summary, image_id)\n",
    "#             atom = tb.Atom.from_dtype(im_mask.dtype)\n",
    "#             filters = tb.Filters(complib='blosc', complevel=9)\n",
    "#             ds = f.create_carray(f.root, image_id, atom, im_mask.shape,\n",
    "#                                  filters=filters)\n",
    "#             ds[:] = im_mask\n",
    "            \n",
    "            \n",
    "def image_mask_resized_from_summary(df, image_id):\n",
    "    im_mask = np.zeros((650, 650))\n",
    "\n",
    "    if len(df[df.ImageId == image_id]) == 0:\n",
    "        raise RuntimeError(\"ImageId not found on summaryData: {}\".format(\n",
    "            image_id))\n",
    "\n",
    "    for idx, row in df[df.ImageId == image_id].iterrows():\n",
    "        shape_obj = shapely.wkt.loads(row.PolygonWKT_Pix)\n",
    "        if shape_obj.exterior is not None:\n",
    "            coords = list(shape_obj.exterior.coords)\n",
    "            x = [round(float(pp[0])) for pp in coords]\n",
    "            y = [round(float(pp[1])) for pp in coords]\n",
    "            yy, xx = skimage.draw.polygon(y, x, (650, 650))\n",
    "            im_mask[yy, xx] = 1\n",
    "\n",
    "            interiors = shape_obj.interiors\n",
    "            for interior in interiors:\n",
    "                coords = list(interior.coords)\n",
    "                x = [round(float(pp[0])) for pp in coords]\n",
    "                y = [round(float(pp[1])) for pp in coords]\n",
    "                yy, xx = skimage.draw.polygon(y, x, (650, 650))\n",
    "                im_mask[yy, xx] = 0\n",
    "#     im_mask = skimage.transform.resize(im_mask, (INPUT_SIZE, INPUT_SIZE))\n",
    "    im_mask = (im_mask > 0.5).astype(np.uint8)\n",
    "    return im_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_train_summary_data(area_id):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    fn = FMT_TRAIN_SUMMARY_PATH.format(prefix=prefix)\n",
    "    df = pd.read_csv(fn)\n",
    "    # df.loc[:, 'ImageId'] = df.ImageId.str[4:]\n",
    "    return df\n",
    "\n",
    "def prep_valtrain_valtest_imagelist(area_id):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    df = _load_train_summary_data(area_id)\n",
    "    df_agg = df.groupby('ImageId').agg('first')\n",
    "\n",
    "    image_id_list = df_agg.index.tolist()\n",
    "    np.random.shuffle(image_id_list)\n",
    "    sz_valtrain = int(len(image_id_list) * 0.7)\n",
    "    sz_valtest = len(image_id_list) - sz_valtrain\n",
    "\n",
    "    base_dir = Path(FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)).parent\n",
    "    if not base_dir.exists():\n",
    "        base_dir.mkdir(parents=True)\n",
    "        (base_dir / Path('list')).mkdir(parents=True)\n",
    "        (base_dir / Path('mask')).mkdir(parents=True)\n",
    "\n",
    "    pd.DataFrame({'ImageId': image_id_list[:sz_valtrain]}).to_csv(\n",
    "        FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix),\n",
    "        index=False)\n",
    "    pd.DataFrame({'ImageId': image_id_list[sz_valtrain:]}).to_csv(\n",
    "        FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix),\n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rgb_multiband_cut_threshold(area_id, datapath):\n",
    "    rows = []\n",
    "    band_cut_th = __calc_rgb_multiband_cut_threshold(area_id, datapath)\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    row = dict(prefix=area_id_to_prefix(area_id))\n",
    "    row['area_id'] = area_id\n",
    "    for chan_i in band_cut_th.keys():\n",
    "        row['chan{}_max'.format(chan_i)] = band_cut_th[chan_i]['max']\n",
    "        row['chan{}_min'.format(chan_i)] = band_cut_th[chan_i]['min']\n",
    "    rows.append(row)\n",
    "    pd.DataFrame(rows).to_csv(\n",
    "        FMT_RGB_BANDCUT_TH_PATH.format(prefix), index=False)\n",
    "\n",
    "\n",
    "def __calc_rgb_multiband_cut_threshold(area_id, datapath):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    band_values = {k: [] for k in range(3)}\n",
    "    band_cut_th = {k: dict(max=0, min=0) for k in range(3)}\n",
    "\n",
    "    image_id_list = pd.read_csv(FMT_VALTRAIN_IMAGELIST_PATH.format(\n",
    "        prefix=prefix)).ImageId.tolist()\n",
    "    for image_id in tqdm.tqdm(image_id_list[:500]):\n",
    "        image_fn = get_train_image_path_from_imageid(image_id, datapath)\n",
    "        with rasterio.open(image_fn, 'r') as f:\n",
    "            values = f.read().astype(np.float32)\n",
    "            for i_chan in range(3):\n",
    "                values_ = values[i_chan].ravel().tolist()\n",
    "                values_ = np.array(\n",
    "                    [v for v in values_ if v != 0]\n",
    "                )  # Remove sensored mask\n",
    "                band_values[i_chan].append(values_)\n",
    "\n",
    "    image_id_list = pd.read_csv(FMT_VALTEST_IMAGELIST_PATH.format(\n",
    "        prefix=prefix)).ImageId.tolist()\n",
    "    for image_id in tqdm.tqdm(image_id_list[:500]):\n",
    "        image_fn = get_train_image_path_from_imageid(image_id, datapath)\n",
    "        with rasterio.open(image_fn, 'r') as f:\n",
    "            values = f.read().astype(np.float32)\n",
    "            for i_chan in range(3):\n",
    "                values_ = values[i_chan].ravel().tolist()\n",
    "                values_ = np.array(\n",
    "                    [v for v in values_ if v != 0]\n",
    "                )  # Remove sensored mask\n",
    "                band_values[i_chan].append(values_)\n",
    "\n",
    "    print(\"Calc percentile point ...\")\n",
    "    for i_chan in range(3):\n",
    "        band_values[i_chan] = np.concatenate(\n",
    "            band_values[i_chan]).ravel()\n",
    "        band_cut_th[i_chan]['max'] = scipy.percentile(\n",
    "            band_values[i_chan], 98)\n",
    "        band_cut_th[i_chan]['min'] = scipy.percentile(\n",
    "            band_values[i_chan], 2)\n",
    "    return band_cut_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_image_path_from_imageid(image_id, datapath, mul=False):\n",
    "    prefix = image_id_to_prefix(image_id)\n",
    "    if mul:\n",
    "        return FMT_TRAIN_MSPEC_IMAGE_PATH.format(\n",
    "            datapath=datapath, prefix=prefix, image_id=image_id)\n",
    "    else:\n",
    "        return FMT_TRAIN_RGB_IMAGE_PATH.format(\n",
    "            datapath=datapath, prefix=prefix, image_id=image_id)\n",
    "\n",
    "\n",
    "def get_test_image_path_from_imageid(image_id, datapath, mul=False):\n",
    "    prefix = image_id_to_prefix(image_id)\n",
    "    if mul:\n",
    "        return FMT_TEST_MSPEC_IMAGE_PATH.format(\n",
    "            datapath=datapath, image_id=image_id)\n",
    "    else:\n",
    "        return FMT_TEST_RGB_IMAGE_PATH.format(\n",
    "            datapath=datapath, image_id=image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_rgb_image_store_train(area_id, datapath, is_valtrain=True):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    bandstats = __load_rgb_bandstats(area_id)\n",
    "\n",
    "    print(\"prep_rgb_image_store_train for {}\".format(prefix))\n",
    "    if is_valtrain:\n",
    "        fn_list = FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)\n",
    "        fn_store = FMT_VALTRAIN_IM_STORE.format(prefix)\n",
    "    else:\n",
    "        fn_list = FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix)\n",
    "        fn_store = FMT_VALTEST_IM_STORE.format(prefix)\n",
    "\n",
    "    df_list = pd.read_csv(fn_list, index_col='ImageId')\n",
    "\n",
    "    print(\"Image store file: {}\".format(fn_store))\n",
    "    for image_id in tqdm.tqdm(df_list.index, total=len(df_list)):\n",
    "        im = get_resized_3chan_image_train(image_id, datapath, bandstats)\n",
    "        plt.imsave(IMAGE_DIR + 'list/' + str(image_id), im)\n",
    "    \n",
    "#     with tb.open_file(fn_store, 'w') as f:\n",
    "#         for image_id in tqdm.tqdm(df_list.index, total=len(df_list)):\n",
    "#             im = get_resized_3chan_image_train(image_id, datapath, bandstats)\n",
    "#             atom = tb.Atom.from_dtype(im.dtype)\n",
    "#             filters = tb.Filters(complib='blosc', complevel=9)\n",
    "#             ds = f.create_carray(f.root, image_id, atom, im.shape,\n",
    "#                                  filters=filters)\n",
    "#             ds[:] = im\n",
    "            \n",
    "def __load_rgb_bandstats(area_id):\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "\n",
    "        >>> __load_rgb_bandstats(3)\n",
    "        {\n",
    "          0: {\n",
    "              'max': 462.0,\n",
    "              'min': 126.0,\n",
    "          },\n",
    "          1: {\n",
    "              'max': 481.0,\n",
    "              'min': 223.0,\n",
    "          },\n",
    "          2: {\n",
    "              'max': 369.0,\n",
    "              'min': 224.0,\n",
    "          },\n",
    "        }\n",
    "    \"\"\"\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    fn_stats = FMT_RGB_BANDCUT_TH_PATH.format(prefix)\n",
    "    df_stats = pd.read_csv(fn_stats, index_col='area_id')\n",
    "    r = df_stats.loc[area_id]\n",
    "\n",
    "    stats_dict = {}\n",
    "    for chan_i in range(3):\n",
    "        stats_dict[chan_i] = dict(\n",
    "            min=r['chan{}_min'.format(chan_i)],\n",
    "            max=r['chan{}_max'.format(chan_i)])\n",
    "    return stats_dict\n",
    "\n",
    "def get_resized_3chan_image_train(image_id, datapath, bandstats):\n",
    "    fn = get_train_image_path_from_imageid(image_id, datapath)\n",
    "    with rasterio.open(fn, 'r') as f:\n",
    "        values = f.read().astype(np.float32)\n",
    "        for chan_i in range(3):\n",
    "            min_val = bandstats[chan_i]['min']\n",
    "            max_val = bandstats[chan_i]['max']\n",
    "            values[chan_i] = np.clip(values[chan_i], min_val, max_val)\n",
    "            values[chan_i] = (values[chan_i] - min_val) / (max_val - min_val)\n",
    "\n",
    "    values = np.swapaxes(values, 0, 2)\n",
    "    values = np.swapaxes(values, 0, 1)\n",
    "#     values = skimage.transform.resize(values, (INPUT_SIZE, INPUT_SIZE))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'data/train/AOI_5_Khartoum_Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'data/train/AOI_4_Shanghai_Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'data/train/AOI_3_Paris_Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'data/train/AOI_2_Vegas_Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproc_test for AOI_2_Vegas\n",
      "AOI_2_Vegas\n"
     ]
    }
   ],
   "source": [
    "area_id = directory_name_to_area_id(datapath)\n",
    "prefix = area_id_to_prefix(area_id)\n",
    "print(\"preproc_test for {}\".format(prefix))\n",
    "prefix = area_id_to_prefix(area_id); print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate IMAGELIST csv\n",
      "Generate IMAGELIST csv ... skip\n"
     ]
    }
   ],
   "source": [
    "# Imagelist\n",
    "if Path(FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)).exists():\n",
    "    print(\"Generate IMAGELIST csv ... skip\")\n",
    "else:\n",
    "    print(\"Generate IMAGELIST csv\")\n",
    "    prep_valtrain_valtest_imagelist(area_id)\n",
    "if Path(FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix)).exists():\n",
    "    print(\"Generate IMAGELIST csv ... skip\")\n",
    "else:\n",
    "    print(\"Generate IMAGELIST csv\")\n",
    "    prep_valtrain_valtest_imagelist(area_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate band stats csv (RGB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:09<00:00,  7.15it/s]\n",
      "100%|██████████| 500/500 [01:11<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calc percentile point ...\n"
     ]
    }
   ],
   "source": [
    "# Band stats (RGB)\n",
    "if Path(FMT_RGB_BANDCUT_TH_PATH.format(prefix)).exists():\n",
    "    print(\"Generate band stats csv (RGB) ... skip\")\n",
    "else:\n",
    "    print(\"Generate band stats csv (RGB)\")\n",
    "    calc_rgb_multiband_cut_threshold(area_id, datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate MASK (valtrain)\n",
      "prep_image_mask for AOI_2_Vegas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2695 [00:00<05:21,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare image container: data/working/images/full_rgb//valtrain_AOI_2_Vegas_mask.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2695/2695 [04:08<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate MASK (valtest)\n",
      "prep_image_mask for AOI_2_Vegas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1156 [00:00<01:27, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare image container: data/working/images/full_rgb//valtest_AOI_2_Vegas_mask.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1156/1156 [01:47<00:00, 10.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Mask (Target output)\n",
    "if Path(FMT_VALTRAIN_MASK_STORE.format(prefix)).exists():\n",
    "    print(\"Generate MASK (valtrain) ... skip\")\n",
    "else:\n",
    "    print(\"Generate MASK (valtrain)\")\n",
    "    prep_image_mask(area_id, is_valtrain=True)\n",
    "if Path(FMT_VALTEST_MASK_STORE.format(prefix)).exists():\n",
    "    print(\"Generate MASK (valtest) ... skip\")\n",
    "else:\n",
    "    print(\"Generate MASK (valtest)\")\n",
    "    prep_image_mask(area_id, is_valtrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2695 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate RGB_STORE (valtrain)\n",
      "prep_rgb_image_store_train for AOI_2_Vegas\n",
      "Image store file: data/working/images/full_rgb//valtrain_AOI_2_Vegas_im.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2498/2695 [13:18<01:02,  3.13it/s]"
     ]
    }
   ],
   "source": [
    "# Image HDF5 store (RGB)\n",
    "if Path(FMT_VALTRAIN_IM_STORE.format(prefix)).exists():\n",
    "    print(\"Generate RGB_STORE (valtrain) ... skip\")\n",
    "else:\n",
    "    print(\"Generate RGB_STORE (valtrain)\")\n",
    "    prep_rgb_image_store_train(area_id, datapath, is_valtrain=True)\n",
    "if Path(FMT_VALTEST_IM_STORE.format(prefix)).exists():\n",
    "    print(\"Generate RGB_STORE (valtest) ... skip\")\n",
    "else:\n",
    "    print(\"Generate RGB_STORE (valtest)\")\n",
    "    prep_rgb_image_store_train(area_id, datapath, is_valtrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
