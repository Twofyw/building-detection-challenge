{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import tables as tb\n",
    "import tqdm\n",
    "\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'code')\n",
    "from models import *\n",
    "from v13_deeplab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'v13'\n",
    "ORIGINAL_SIZE = 650\n",
    "sz = 256\n",
    "num_slice = 9\n",
    "STRIDE_SZ = 197\n",
    "PATH = 'data/'\n",
    "\n",
    "num_gpus = 3\n",
    "num_workers = 4 * num_gpus\n",
    "gpu_start = 4\n",
    "device_ids = range(gpu_start, gpu_start + num_gpus)\n",
    "torch.cuda.set_device(gpu_start)\n",
    "\n",
    "bs = 35 * num_gpus \n",
    "BASE_DIR = \"data/train\"\n",
    "BASE_TEST_DIR = \"data/test\"\n",
    "WORKING_DIR = \"data/working\"\n",
    "\n",
    "# Restore later\n",
    "IMAGE_DIR = \"data/working/images/{}\".format('v12')\n",
    "# IMAGE_DIR = \"data/working/images/{}\".format('v5')\n",
    "V5_IMAGE_DIR = \"data/working/images/{}\".format('v5')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Parameters\n",
    "MIN_POLYGON_AREA = 30  # 30\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Input files\n",
    "FMT_TRAIN_SUMMARY_PATH = str(\n",
    "    Path(BASE_DIR) /\n",
    "    Path(\"{prefix:s}_Train/\") /\n",
    "    Path(\"summaryData/{prefix:s}_Train_Building_Solutions.csv\"))\n",
    "FMT_TRAIN_RGB_IMAGE_PATH = str(\n",
    "    Path(BASE_DIR) /\n",
    "    Path(\"{prefix:s}_Train/\") /\n",
    "    Path(\"RGB-PanSharpen/RGB-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TEST_RGB_IMAGE_PATH = str(\n",
    "    Path(BASE_TEST_DIR) /\n",
    "    Path(\"{prefix:s}_Test/\") /\n",
    "    Path(\"RGB-PanSharpen/RGB-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TRAIN_MSPEC_IMAGE_PATH = str(\n",
    "    Path(BASE_DIR) /\n",
    "    Path(\"{prefix:s}_Train/\") /\n",
    "    Path(\"MUL-PanSharpen/MUL-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TEST_MSPEC_IMAGE_PATH = str(\n",
    "    Path(BASE_TEST_DIR) /\n",
    "    Path(\"{prefix:s}_Test/\") /\n",
    "    Path(\"MUL-PanSharpen/MUL-PanSharpen_{image_id:s}.tif\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Preprocessing result\n",
    "FMT_RGB_BANDCUT_TH_PATH = IMAGE_DIR + \"/rgb_bandcut.csv\"\n",
    "FMT_MUL_BANDCUT_TH_PATH = IMAGE_DIR + \"/mul_bandcut.csv\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Image list, Image container and mask container\n",
    "FMT_VALTRAIN_IM_FOLDER = V5_IMAGE_DIR + \"/trn_full_rgb/\"\n",
    "FMT_VALTEST_IM_FOLDER = V5_IMAGE_DIR + \"/test_full_rgb/\"\n",
    "\n",
    "FMT_VALTRAIN_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_valtrain_ImageId.csv\"\n",
    "FMT_VALTEST_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_valtest_ImageId.csv\"\n",
    "FMT_VALTRAIN_IM_STORE = IMAGE_DIR + \"/valtrain_{}_im.h5\"\n",
    "FMT_VALTEST_IM_STORE = IMAGE_DIR + \"/valtest_{}_im.h5\"\n",
    "# FMT_VALTRAIN_MASK_STORE = IMAGE_DIR + \"/valtrain_{}_mask.h5\"\n",
    "# FMT_VALTEST_MASK_STORE = IMAGE_DIR + \"/valtest_{}_mask.h5\"\n",
    "FMT_VALTRAIN_MASK_STORE = V5_IMAGE_DIR + \"/valtrain_{}_mask.h5\"\n",
    "FMT_VALTEST_MASK_STORE = V5_IMAGE_DIR + \"/valtest_{}_mask.h5\"\n",
    "# FMT_VALTRAIN_MUL_STORE = IMAGE_DIR + \"/valtrain_{}_mul.h5\"\n",
    "# FMT_VALTEST_MUL_STORE = IMAGE_DIR + \"/valtest_{}_mul.h5\"\n",
    "FMT_VALTRAIN_MUL_STORE = V5_IMAGE_DIR + \"/valtrain_{}_mul.h5\"\n",
    "FMT_VALTEST_MUL_STORE = V5_IMAGE_DIR + \"/valtest_{}_mul.h5\"\n",
    "\n",
    "FMT_TRAIN_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_train_ImageId.csv\"\n",
    "FMT_TEST_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_test_ImageId.csv\"\n",
    "FMT_TRAIN_IM_STORE = IMAGE_DIR + \"/train_{}_im.h5\"\n",
    "FMT_TEST_IM_STORE = IMAGE_DIR + \"/test_{}_im.h5\"\n",
    "FMT_TRAIN_MASK_STORE = IMAGE_DIR + \"/train_{}_mask.h5\"\n",
    "FMT_TRAIN_MUL_STORE = IMAGE_DIR + \"/train_{}_mul.h5\"\n",
    "FMT_TEST_MUL_STORE = IMAGE_DIR + \"/test_{}_mul.h5\"\n",
    "FMT_IMMEAN = V5_IMAGE_DIR + \"/{}_immean.h5\"\n",
    "FMT_MULMEAN = IMAGE_DIR + \"/{}_mulmean.h5\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Model files\n",
    "MODEL_DIR = \"data/working/models/{}\".format(MODEL_NAME)\n",
    "FMT_VALMODEL_PATH = MODEL_DIR + \"/{}_val_weights.h5\"\n",
    "FMT_FULLMODEL_PATH = MODEL_DIR + \"/{}_full_weights.h5\"\n",
    "FMT_VALMODEL_HIST = MODEL_DIR + \"/{}_val_hist.csv\"\n",
    "FMT_VALMODEL_EVALHIST = MODEL_DIR + \"/{}_val_evalhist.csv\"\n",
    "FMT_VALMODEL_EVALTHHIST = MODEL_DIR + \"/{}_val_evalhist_th.csv\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Prediction & polygon result\n",
    "FMT_TESTPRED_PATH = MODEL_DIR + \"/{}_pred.h5\"\n",
    "FMT_VALTESTPRED_PATH = MODEL_DIR + \"/{}_eval_pred.h5\"\n",
    "FMT_VALTESTPOLY_PATH = MODEL_DIR + \"/{}_eval_poly.csv\"\n",
    "FMT_VALTESTTRUTH_PATH = MODEL_DIR + \"/{}_eval_poly_truth.csv\"\n",
    "FMT_VALTESTPOLY_OVALL_PATH = MODEL_DIR + \"/eval_poly.csv\"\n",
    "FMT_VALTESTTRUTH_OVALL_PATH = MODEL_DIR + \"/eval_poly_truth.csv\"\n",
    "FMT_TESTPOLY_PATH = MODEL_DIR + \"/{}_poly.csv\"\n",
    "FN_SOLUTION_CSV = \"data/output/{}.csv\".format(MODEL_NAME)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Model related files (others)\n",
    "FMT_VALMODEL_LAST_PATH = MODEL_DIR + \"/{}_val_weights_last.h5\"\n",
    "FMT_FULLMODEL_LAST_PATH = MODEL_DIR + \"/{}_full_weights_last.h5\"\n",
    "\n",
    "datapaths = ['data/train/AOI_3_Paris_Train', 'data/train/AOI_2_Vegas_Train', 'data/train/AOI_4_Shanghai_Train', 'data/train/AOI_5_Khartoum_Train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapaths = ['data/train/AOI_2_Vegas_Train', 'data/train/AOI_3_Paris_Train', 'data/train/AOI_4_Shanghai_Train', 'data/train/AOI_5_Khartoum_Train']\n",
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[0]}\n",
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in datapaths: print(d, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !parallel python code/v5_im-full_rgb.py preproc_train {} ::: data/train/AOI_2_Vegas_Train data/train/AOI_3_Paris_Train data/train/AOI_4_Shanghai_Train data/train/AOI_5_Khartoum_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_path in ['data/train/AOI_2_Vegas_Train', 'data/train/AOI_3_Paris_Train', 'data/train/AOI_4_Shanghai_Train', 'data/train/AOI_5_Khartoum_Train']:\n",
    "#     !python code/v12_im_deeplab.py preproc_train {train_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(area_id, is_test, max_workers=3):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    fn_train = FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix) if is_test else FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)\n",
    "    df_train = pd.read_csv(fn_train)\n",
    "    \n",
    "    fn_im = FMT_VALTEST_MASK_STORE.format(prefix) if is_test else FMT_VALTRAIN_MASK_STORE.format(prefix)\n",
    "    y_val = np.empty((df_train.shape[0], ORIGINAL_SIZE, ORIGINAL_SIZE, 1))\n",
    "    with tb.open_file(fn_im, 'r') as f:                                         \n",
    "        for i, image_id in tqdm.tqdm_notebook(enumerate(df_train.ImageId.tolist()), total=df_train.shape[0], desc='ims'):\n",
    "            fn = '/' + image_id\n",
    "            y_val[i] = np.array(f.get_node(fn))[..., None]\n",
    "            \n",
    "    fn_im = FMT_VALTEST_IM_FOLDER if is_test else FMT_VALTRAIN_IM_FOLDER\n",
    "    X_val = np.empty((df_train.shape[0], ORIGINAL_SIZE, ORIGINAL_SIZE, 3))\n",
    "    if max_workers == 1:\n",
    "        for i, image_id in tqdm.tqdm_notebook(enumerate(df_train.ImageId.tolist()), total=df_train.shape[0], desc='ims'):\n",
    "            X_val[i] = plt.imread(fn_im + image_id + '.png')[...,:3]\n",
    "    else:\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as e:\n",
    "            gen = e.map(plt.imread, [fn_im + image_id + '.png' for image_id in df_train.ImageId.tolist()])\n",
    "            for i, im in enumerate(gen):\n",
    "                X_val[i] = im[...,:3]\n",
    "#         im = np.moveaxis(im, -1, 0)\n",
    "\n",
    "    X_val, y_val = X_val.astype('float'), y_val.astype('float')\n",
    "    return X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'a'\n",
    "a != ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory dataset\n",
    "def get_dataset(datapath):\n",
    "    area_id = directory_name_to_area_id(datapath)\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    trn_x, trn_y = get_data(area_id, False)\n",
    "#     print(trn_x.shape, trn_y.shape)\n",
    "#     trn_x = np.moveaxis(trn_x, 1, -1).astype('float') # --> [bs, h, w, ch]\n",
    "#     trn_y = np.moveaxis(trn_y, 1, -1).astype('float')\n",
    "\n",
    "#     print(trn_x.shape, trn_y.shape)\n",
    "    trn_y = np.broadcast_to(trn_y, [trn_y.shape[0], ORIGINAL_SIZE, ORIGINAL_SIZE, 3])\n",
    "\n",
    "    val_x, val_y = get_data(area_id, True)\n",
    "#     val_x = val_x[:,:3]\n",
    "#     val_x = np.moveaxis(val_x, 1, -1).astype('float')\n",
    "#     val_y = val_y[:,:3]\n",
    "#     val_y = np.moveaxis(val_y, 1, -1).astype('float')\n",
    "    val_y = np.broadcast_to(val_y, [val_y.shape[0], ORIGINAL_SIZE, ORIGINAL_SIZE, 3])\n",
    "               \n",
    "    return (trn_x,trn_y), (val_x,val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArraysSingleDataset(BaseDataset):\n",
    "    def __init__(self, is_trn, y, transform):\n",
    "        # input: ch x w x h\n",
    "        global trn_x, trn_y, val_x, val_y\n",
    "#         if is_trn:\n",
    "#             self.x = trn_x; self.y = trn_y\n",
    "#         else:\n",
    "#             self.x = val_x; self.y = val_y\n",
    "        self.is_trn = is_trn\n",
    "#         self.num_groups = len(x)\n",
    "        self.sz = trn_x[0].shape[1] if self.is_trn else val_x[0].shape[1]\n",
    "#         self.ns = np.array([o.shape[0] for o in x])\n",
    "#         self.cum_ns = np.cumsum(self.ns * num_slice)\n",
    "        super().__init__(transform)\n",
    "\n",
    "        \n",
    "    def get_im(self, i, is_y):\n",
    "#         idx_file, idx_im = self.get_file_idx(i)\n",
    "        if is_y:\n",
    "            im = trn_y[i//num_slice] if self.is_trn else val_y[i//num_slice]\n",
    "        else:\n",
    "            im = trn_x[i//num_slice] if self.is_trn else val_x[i//num_slice]\n",
    "#         slice_pos = idx_im % num_slice\n",
    "#         a = np.sqrt(num_slice)\n",
    "#         cut_i = slice_pos // a\n",
    "#         cut_j = slice_pos % a\n",
    "#         stride = (self.sz - sz) // a\n",
    "#         cut_x = int(cut_j * stride)\n",
    "#         cut_y = int(cut_i * stride)\n",
    "        slice_pos = i % num_slice\n",
    "        a = np.sqrt(num_slice)\n",
    "        cut_i = slice_pos // a\n",
    "        cut_j = slice_pos % a\n",
    "        stride = (self.sz - sz) // a\n",
    "        cut_x = int(cut_j * stride)\n",
    "        cut_y = int(cut_i * stride)\n",
    "        return im[cut_x:cut_x + sz, cut_y:cut_y + sz]\n",
    "        \n",
    "            \n",
    "    def get_x(self, i): return self.get_im(i, False)\n",
    "    def get_y(self, i): return self.get_im(i, True)\n",
    "        \n",
    "#     def get_file_idx(self, i):\n",
    "#         idx_file = np.argmax(i + 1 <= self.cum_ns)\n",
    "#         if idx_file == 0:\n",
    "#             idx_im = i\n",
    "#         else:\n",
    "#             idx_im = i - self.cum_ns[idx_file - 1]\n",
    "#         return idx_file, idx_im\n",
    "    \n",
    "    def get_n(self): return trn_x.shape[0] * num_slice if self.is_trn else val_x.shape[0] * num_slice\n",
    "    \n",
    "    def get_sz(self): return self.sz\n",
    "        \n",
    "    def get_c(self): return 1\n",
    "    def denorm(self, arr):\n",
    "        \"\"\"Reverse the normalization done to a batch of images.\n",
    "\n",
    "        Arguments:\n",
    "            arr: of shape/size (N,3,sz,sz)\n",
    "        \"\"\"\n",
    "        if type(arr) is not np.ndarray: arr = to_np(arr)\n",
    "        if len(arr.shape)==3: arr = arr[None]\n",
    "#         return np.clip(self.transform.denorm(np.rollaxis(arr,1,4)), 0, 1)\n",
    "        return self.transform.denorm(np.rollaxis(arr,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_base = 8\n",
    "class UpsampleModel():\n",
    "    def __init__(self,model,name='upsample'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        c = list(children(self.model.module))\n",
    "        return [c[:cut_base],\n",
    "               c[cut_base:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_iou(y_pred, y_true, thresh=0.5):\n",
    "    return np.array([jaccard_coef(p, t) for (p, t) in zip(y_pred, y_true)])\n",
    "    \n",
    "## cuda version\n",
    "def jaccard_coef_cuda(y_pred, y_true, thresh=0.5):\n",
    "    smooth = T(1e-12)\n",
    "    y_pred = (y_pred > thresh).float()\n",
    "    y_true = (y_true > thresh).float()\n",
    "    intersection = y_true * y_pred\n",
    "    sum_ = torch.sum(y_true + y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return torch.mean(jac)\n",
    "\n",
    "## np version\n",
    "def jaccard_coef(y_pred, y_true=None, thresh=0.5):\n",
    "    if isinstance(y_pred, tuple):\n",
    "        y_pred, y_true = y_pred\n",
    "    elif y_true is None:\n",
    "        raise TypeError\n",
    "        \n",
    "    smooth = 1e-12\n",
    "    y_pred = to_np(y_pred) > thresh\n",
    "    y_true = to_np(y_true) > thresh\n",
    "    intersection = y_true * y_pred\n",
    "    sum_ = np.sum(y_true) + np.sum(y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return np.mean(jac)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def jaccard_coef_parallel(y_pred, y_true, thresh=0.5, num_workers=8):\n",
    "    if num_workers == 0:\n",
    "        return jaccard_coef(y_pred, y_true, thresh=0.5)\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as e:\n",
    "        jac = list(e.map(jaccard_coef, zip(y_pred, y_true)))\n",
    "        return np.mean(jac)\n",
    "        \n",
    "\n",
    "# def jaccard_coef_int(y_true, y_pred):\n",
    "#     smooth = 1e-12\n",
    "#     y_true = torch.round(y_true)\n",
    "#     y_pred_pos = torch.round(torch.clamp(y_pred, 0, 1))\n",
    "#     intersection = torch.sum(y_true * y_pred_pos)\n",
    "#     sum_ = torch.sum(y_true + y_pred_pos)\n",
    "#     jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "#     return jac.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = np.zeros((2000,256,256))\n",
    "# t2 = np.ones((2000,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time jaccard_coef(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(1, 24, 2):\n",
    "#     %time jaccard_coef_parallel(t1, t2, num_workers=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_workers :== 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_mean_stat(area_id):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "\n",
    "    with tb.open_file(FMT_IMMEAN.format(prefix), 'r') as f:\n",
    "        im_mean = np.array(f.get_node('/immean'))[:3]\n",
    "    \n",
    "    mean = [np.mean(im_mean[i]) for i in range(3)]\n",
    "    std = [np.std(im_mean[i]) for i in range(3)]\n",
    "    return np.stack([np.array(mean), np.array(std)])\n",
    "\n",
    "def get_md_model(datapaths, device_ids=device_ids):\n",
    "#     (trn_x, trn_y), (val_x, val_y) = trn, val\n",
    "    aug_tfms = transforms_top_down\n",
    "    for o in aug_tfms: o.tfm_y = TfmType.CLASS\n",
    "        \n",
    "    area_ids = [directory_name_to_area_id(datapath) for datapath in datapaths]\n",
    "    stats = np.mean([get_rgb_mean_stat(area_id) for area_id in area_ids], axis=0)\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "    \n",
    "    datasets = ImageData.get_ds(ArraysSingleDataset, (True, True), (False, False), tfms)\n",
    "    md = ImageData('data', datasets, bs, num_workers=num_workers, classes=None)\n",
    "    denorm = md.trn_ds.denorm\n",
    "\n",
    "    if not Path(MODEL_DIR).exists():\n",
    "        Path(MODEL_DIR).mkdir(parents=True)\n",
    "\n",
    "    net = to_gpu(UNet16(pretrained='vgg'))\n",
    "    net = nn.DataParallel(net, device_ids)\n",
    "    models = UpsampleModel(net)\n",
    "    return md, models, denorm\n",
    "\n",
    "def expanded_loss(pred, target):\n",
    "#     pred = torch.clamp(pred, 0, 1)\n",
    "    return F.binary_cross_entropy_with_logits(pred[:,0], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trn_x,trn_y), (val_x,val_y) = (None, None), (None, None)\n",
    "last_datapath = None\n",
    "crit=expanded_loss\n",
    "metrics = jaccard_coef_parallel\n",
    "\n",
    "def learner_on_dataset(datapath):\n",
    "    global trn_x, trn_y, val_x, val_y\n",
    "    global last_datapath\n",
    "    \n",
    "    last_datapath = datapaths\n",
    "    (trn_x,trn_y), (val_x,val_y) = get_dataset(datapath)\n",
    "    md, model, denorm = get_md_model([datapath])\n",
    "    print('Data finished loading:', datapath)\n",
    "    learn=ConvLearner(md, model)\n",
    "    learn.opt_fn=optim.Adam\n",
    "    learn.crit=crit\n",
    "    learn.metrics=[metrics]\n",
    "    return learn, denorm\n",
    "\n",
    "def load_backup_learn():\n",
    "    global trn_x, trn_y, val_x, val_y\n",
    "    global last_datapath\n",
    "    \n",
    "    md, model, denorm = get_md_model(last_datapath)\n",
    "    learn=convlearner(md, model)\n",
    "    learn.opt_fn=optim.Adam\n",
    "    learn.crit=crit\n",
    "    learn.metrics=[metrics]\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_plot(idx, fn, lrs, epoch=1, wds=None, cycle_len=8, **kwargs):\n",
    "    kwargs['cycle_len'] = cycle_len\n",
    "    learn.fit(lrs, epoch, wds, **kwargs)\n",
    "    plt.subplots(1, 2, figsize=(10, 5))\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(121)\n",
    "    plt.plot(learn.sched.iterations, learn.sched.losses)\n",
    "    plt.xlabel('loss')\n",
    "    plt.subplot(122)\n",
    "    plt.plot(learn.sched.iterations, learn.sched.lrs)\n",
    "    plt.xlabel('lr')\n",
    "    learn.save(fn + '_' + str(idx))\n",
    "    \n",
    "def after_train_plot():\n",
    "    plt.subplots(1, 2, figsize=(10, 5))\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(121)\n",
    "    plt.plot(learn.sched.iterations, learn.sched.losses)\n",
    "    plt.subplot(122)\n",
    "    plt.plot(learn.sched.iterations, learn.sched.lrs)\n",
    "    \n",
    "def bool_pred(pred, thresh=0.5):\n",
    "    return to_np(pred > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worse(tta, shift=0, n_ims=9, is_best=False):\n",
    "    tta_exp = np.mean(np.exp(tta[0]), axis=0).squeeze()\n",
    "    ious = sep_iou(tta_exp, tta[1])\n",
    "    lowest_iou_idx = np.argsort(ious)\n",
    "    if is_best:\n",
    "        lowest_iou_idx = np.flip(lowest_iou_idx, 0)\n",
    "    \n",
    "    col = 4\n",
    "    plt.subplots(n_ims, 4, figsize=(15,30))\n",
    "    \n",
    "    for i in range(n_ims):\n",
    "        x, _ = learn.data.fix_dl.get_batch([lowest_iou_idx[i + shift]])\n",
    "        plt.subplot(n_ims, col, i * col + 1)\n",
    "        plt.xlabel('rgb')\n",
    "        plt.imshow(denorm(x)[0])\n",
    "\n",
    "        plt.subplot(n_ims, col, i * col + 2)\n",
    "        plt.imshow(tta_exp[lowest_iou_idx[i + shift]])\n",
    "        plt.xlabel('Prediction: iou = ' + str(ious[lowest_iou_idx[i + shift]]))\n",
    "        \n",
    "        plt.subplot(n_ims, col, i * col + 3)\n",
    "        plt.imshow(bool_pred(tta_exp[lowest_iou_idx[i + shift]], 0.5))\n",
    "        plt.xlabel('bool_pred')\n",
    "\n",
    "        plt.subplot(n_ims, col, i * col + 4)\n",
    "        plt.imshow(tta[1][lowest_iou_idx[i + shift]])\n",
    "        plt.xlabel('GT')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = None\n",
    "# sequential: if True, in one outer loop, every dataset is trained only once\n",
    "def train_on_full_dataset(epochs, lrs, wds, sequential=False, save_starter='full_dataset_beginner', cycle_len=2, cycle_mult=2):\n",
    "    global learn\n",
    "    for out_epoch in tqdm.tnrange(epochs if sequential else 1, desc='out'):\n",
    "        for i, datapath in tqdm.tqdm_notebook(enumerate(datapaths), total=len(datapaths), desc='datapaths'):\n",
    "            learn, denorm = learner_on_dataset(datapath)\n",
    "            \n",
    "            best_save_name = 'full_dataset_out' if sequential else 'full_dataset_in'\n",
    "            epoch_save_name_base = 'full_dataset'\n",
    "            epoch_save_name_base += '_out_' if sequential else '_in_'\n",
    "            \n",
    "            print('epoch:', out_epoch)\n",
    "            if i:\n",
    "                learn.load(epoch_save_name_base + str(i - 1))\n",
    "            elif save_starter != '':\n",
    "                learn.load(save_starter)\n",
    "            \n",
    "            learn.unfreeze();\n",
    "            in_epochs = epochs if not sequential else 1\n",
    "            %time learn.fit(lrs, in_epochs, wds=wds, use_wd_sched=True, cycle_len=cycle_len,\\\n",
    "                            cycle_mult=cycle_mult, use_clr=None, best_save_name=best_save_name)\n",
    "\n",
    "            learn.save(epoch_save_name_base + str(i))\n",
    "            \n",
    "            plt.subplots(1, 2, figsize=(10, epochs * 5))\n",
    "            plt.tight_layout()\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(learn.sched.iterations, learn.sched.losses)\n",
    "            plt.xlabel('loss')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(learn.sched.iterations, learn.sched.lrs)\n",
    "            plt.xlabel('lr')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012119c2d0f1436e8fb3e4d99c06d2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='out', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4226b0ddd7444769ea0d0c364e68bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='datapaths', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200abad50fc14521bdf29c9eacf7b212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=803), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bb50fdee44465cb268cf6252d9f6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=803), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e9d5216d6d4849a7a0caf0c330109b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab4a148ab6040428f155d8bcd689f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data finished loading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9e642c4bc74d8b8615f8beaef1690d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   jaccard_coef_parallel     \n",
      "    0      0.452091   0.32929    0.582287  \n",
      "    1      0.571771   0.691234   0.582287                  \n",
      "    2      0.663215   0.691448   0.582287                  \n",
      "    3      0.684682   0.691809   0.582287                  \n",
      "    4      0.690376   0.692492   0.582287                  \n",
      "    5      0.692222   0.692985   0.582287                  \n",
      "    6      0.692058   0.691627   0.582287                  \n",
      "    7      0.691693   0.691533   0.582287                  \n",
      "    8      0.691688   0.691742   0.582287                  \n",
      "    9      0.691892   0.692055   0.582287                  \n",
      "    10     0.692189   0.692399   0.582287                  \n",
      "    11     0.692507   0.692719   0.582287                  \n",
      "    12     0.69279    0.692966   0.582287                  \n",
      "    13     0.692994   0.693104   0.582287                  \n",
      "    14     0.692316   0.691692   0.582287                  \n",
      "    15     0.69176    0.691482   0.582287                  \n",
      "    16     0.69159    0.691504   0.582287                  \n",
      "    17     0.691596   0.691593   0.582287                  \n",
      "    18     0.691678   0.691712   0.582287                  \n",
      "    19     0.691794   0.691854   0.582287                  \n",
      "    20     0.691933   0.692009   0.582287                  \n",
      "    21     0.692087   0.692176   0.582287                  \n",
      "    22     0.692249   0.692346   0.582287                  \n",
      "    23     0.692414   0.692514   0.582287                  \n",
      "    24     0.692572   0.692672   0.582287                  \n",
      "    25     0.692721   0.692814   0.582287                  \n",
      "    26     0.692854   0.692937   0.582287                  \n",
      "    27     0.692965   0.693033   0.582287                  \n",
      "    28     0.69305    0.693101   0.582287                  \n",
      "    29     0.693107   0.693136   0.582287                  \n",
      "CPU times: user 10h 40min 11s, sys: 11h 26min 11s, total: 22h 6min 23s\n",
      "Wall time: 1h 5min 57s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d752883ae3d343c9ae856e993c1ef560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=2695), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b25a9d4ceb3466d9229516e334e7913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=2695), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78d2bcdaee54de7aa3290ec26d4fb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=1156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87ddda9bee04a46a438e6c82f330e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ims', max=1156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data finished loading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c09ec524de40c5b68107b6c217ac96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 118/231 [02:56<02:49,  1.50s/it, loss=0.476]"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "lrs = np.array([lr/3, lr])\n",
    "wd = 0.025\n",
    "wds = [wd/3, wd]\n",
    "train_on_full_dataset(4, lrs, wds, False, save_starter='full_dataset_beginner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('autosaved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_backup_learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Train from scratch, 8 workers\n",
    "lr = 1e-3\n",
    "lrs = np.array([lr/3, lr])\n",
    "wd = 0.025\n",
    "wds = [wd/10, wd]\n",
    "train_and_plot(0, 'vegas', epoch=1, lrs=lrs, wds=wds, cycle_len=8, use_clr=(20,8), use_wd_sched=True, best_save_name='autosaved_vegas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('vegas_scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('vegas_scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "learn.bn_freeze(False)\n",
    "lrs = np.array([lr/3, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Traing with 16 workers\n",
    "train_and_plot(0, 'vegas', epoch=1, lrs=lrs, wds=wds, cycle_len=8, use_clr=(20,8), use_wd_sched=True, best_save_name='autosaved_vegas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('vegas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## 24 workers\n",
    "lr = 1e-5\n",
    "lrs = np.array([lr/3, lr])\n",
    "train_and_plot(1, 'vegas', epoch=2, lrs=lrs, wds=wds, use_wd_sched=True, cycle_len=8, use_clr=None, best_save_name='autosaved_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tta = learn.TTA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tta = learn.TTA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = learn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_worse(tta, shift=3000, n_ims=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
