{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import tables as tb\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'code')\n",
    "from models import *\n",
    "from v13_deeplab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'v13'\n",
    "ORIGINAL_SIZE = 650\n",
    "sz = 256\n",
    "bs = 200\n",
    "num_slice = 9\n",
    "STRIDE_SZ = 197\n",
    "PATH = 'data/'\n",
    "\n",
    "BASE_DIR = \"data/train\"\n",
    "BASE_TEST_DIR = \"data/test\"\n",
    "WORKING_DIR = \"data/working\"\n",
    "\n",
    "# Restore later\n",
    "IMAGE_DIR = \"data/working/images/{}\".format('v12')\n",
    "# IMAGE_DIR = \"data/working/images/{}\".format('v5')\n",
    "V5_IMAGE_DIR = \"data/working/images/{}\".format('v5')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Parameters\n",
    "MIN_POLYGON_AREA = 30  # 30\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Input files\n",
    "FMT_TRAIN_SUMMARY_PATH = str(\n",
    "    Path(BASE_DIR) /\n",
    "    Path(\"{prefix:s}_Train/\") /\n",
    "    Path(\"summaryData/{prefix:s}_Train_Building_Solutions.csv\"))\n",
    "FMT_TRAIN_RGB_IMAGE_PATH = str(\n",
    "    Path(BASE_DIR) /\n",
    "    Path(\"{prefix:s}_Train/\") /\n",
    "    Path(\"RGB-PanSharpen/RGB-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TEST_RGB_IMAGE_PATH = str(\n",
    "    Path(BASE_TEST_DIR) /\n",
    "    Path(\"{prefix:s}_Test/\") /\n",
    "    Path(\"RGB-PanSharpen/RGB-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TRAIN_MSPEC_IMAGE_PATH = str(\n",
    "    Path(BASE_DIR) /\n",
    "    Path(\"{prefix:s}_Train/\") /\n",
    "    Path(\"MUL-PanSharpen/MUL-PanSharpen_{image_id:s}.tif\"))\n",
    "FMT_TEST_MSPEC_IMAGE_PATH = str(\n",
    "    Path(BASE_TEST_DIR) /\n",
    "    Path(\"{prefix:s}_Test/\") /\n",
    "    Path(\"MUL-PanSharpen/MUL-PanSharpen_{image_id:s}.tif\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Preprocessing result\n",
    "FMT_RGB_BANDCUT_TH_PATH = IMAGE_DIR + \"/rgb_bandcut.csv\"\n",
    "FMT_MUL_BANDCUT_TH_PATH = IMAGE_DIR + \"/mul_bandcut.csv\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Image list, Image container and mask container\n",
    "FMT_VALTRAIN_IM_FOLDER = V5_IMAGE_DIR + \"/trn_full_rgb/\"\n",
    "FMT_VALTEST_IM_FOLDER = V5_IMAGE_DIR + \"/trn_full_rgb/\"\n",
    "\n",
    "FMT_VALTRAIN_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_valtrain_ImageId.csv\"\n",
    "FMT_VALTEST_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_valtest_ImageId.csv\"\n",
    "FMT_VALTRAIN_IM_STORE = IMAGE_DIR + \"/valtrain_{}_im.h5\"\n",
    "FMT_VALTEST_IM_STORE = IMAGE_DIR + \"/valtest_{}_im.h5\"\n",
    "# FMT_VALTRAIN_MASK_STORE = IMAGE_DIR + \"/valtrain_{}_mask.h5\"\n",
    "# FMT_VALTEST_MASK_STORE = IMAGE_DIR + \"/valtest_{}_mask.h5\"\n",
    "FMT_VALTRAIN_MASK_STORE = V5_IMAGE_DIR + \"/valtrain_{}_mask.h5\"\n",
    "FMT_VALTEST_MASK_STORE = V5_IMAGE_DIR + \"/valtest_{}_mask.h5\"\n",
    "# FMT_VALTRAIN_MUL_STORE = IMAGE_DIR + \"/valtrain_{}_mul.h5\"\n",
    "# FMT_VALTEST_MUL_STORE = IMAGE_DIR + \"/valtest_{}_mul.h5\"\n",
    "FMT_VALTRAIN_MUL_STORE = V5_IMAGE_DIR + \"/valtrain_{}_mul.h5\"\n",
    "FMT_VALTEST_MUL_STORE = V5_IMAGE_DIR + \"/valtest_{}_mul.h5\"\n",
    "\n",
    "FMT_TRAIN_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_train_ImageId.csv\"\n",
    "FMT_TEST_IMAGELIST_PATH = V5_IMAGE_DIR + \"/{prefix:s}_test_ImageId.csv\"\n",
    "FMT_TRAIN_IM_STORE = IMAGE_DIR + \"/train_{}_im.h5\"\n",
    "FMT_TEST_IM_STORE = IMAGE_DIR + \"/test_{}_im.h5\"\n",
    "FMT_TRAIN_MASK_STORE = IMAGE_DIR + \"/train_{}_mask.h5\"\n",
    "FMT_TRAIN_MUL_STORE = IMAGE_DIR + \"/train_{}_mul.h5\"\n",
    "FMT_TEST_MUL_STORE = IMAGE_DIR + \"/test_{}_mul.h5\"\n",
    "FMT_MULMEAN = IMAGE_DIR + \"/{}_mulmean.h5\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Model files\n",
    "MODEL_DIR = \"data/working/models/{}\".format(MODEL_NAME)\n",
    "FMT_VALMODEL_PATH = MODEL_DIR + \"/{}_val_weights.h5\"\n",
    "FMT_FULLMODEL_PATH = MODEL_DIR + \"/{}_full_weights.h5\"\n",
    "FMT_VALMODEL_HIST = MODEL_DIR + \"/{}_val_hist.csv\"\n",
    "FMT_VALMODEL_EVALHIST = MODEL_DIR + \"/{}_val_evalhist.csv\"\n",
    "FMT_VALMODEL_EVALTHHIST = MODEL_DIR + \"/{}_val_evalhist_th.csv\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Prediction & polygon result\n",
    "FMT_TESTPRED_PATH = MODEL_DIR + \"/{}_pred.h5\"\n",
    "FMT_VALTESTPRED_PATH = MODEL_DIR + \"/{}_eval_pred.h5\"\n",
    "FMT_VALTESTPOLY_PATH = MODEL_DIR + \"/{}_eval_poly.csv\"\n",
    "FMT_VALTESTTRUTH_PATH = MODEL_DIR + \"/{}_eval_poly_truth.csv\"\n",
    "FMT_VALTESTPOLY_OVALL_PATH = MODEL_DIR + \"/eval_poly.csv\"\n",
    "FMT_VALTESTTRUTH_OVALL_PATH = MODEL_DIR + \"/eval_poly_truth.csv\"\n",
    "FMT_TESTPOLY_PATH = MODEL_DIR + \"/{}_poly.csv\"\n",
    "FN_SOLUTION_CSV = \"data/output/{}.csv\".format(MODEL_NAME)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Model related files (others)\n",
    "FMT_VALMODEL_LAST_PATH = MODEL_DIR + \"/{}_val_weights_last.h5\"\n",
    "FMT_FULLMODEL_LAST_PATH = MODEL_DIR + \"/{}_full_weights_last.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-12 00:02:02,364 INFO Preproc for training on AOI_3_Paris\n",
      "2018-04-12 00:02:02,364 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:02:02,364 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:02:02,364 INFO Generate band stats csv (RGB) ... skip\n",
      "2018-04-12 00:02:02,364 INFO Generate MASK (valtrain) ... skip\n",
      "2018-04-12 00:02:02,365 INFO Generate MASK (valtest) ... skip\n",
      "2018-04-12 00:02:02,365 INFO Generate RGB_STORE (valtrain)\n",
      "2018-04-12 00:02:02,370 INFO prep_rgb_image_store_train for AOI_3_Paris\n",
      "2018-04-12 00:02:02,372 INFO Image store file: data/working/images/v5/trn_full_rgb/\n",
      "2018-04-12 00:06:03,924 INFO Generate RGB_STORE (valtest)\n",
      "2018-04-12 00:06:03,937 INFO prep_rgb_image_store_train for AOI_3_Paris\n",
      "2018-04-12 00:06:03,939 INFO Image store file: data/working/images/v5/test_full_rgb/\n",
      "2018-04-12 00:07:45,233 INFO Generate RGBMEAN\n",
      "2018-04-12 00:08:13,445 INFO Prepare mean image: data/working/images/v5/AOI_3_Paris_immean.h5\n",
      "2018-04-12 00:08:13,538 INFO Preproc for training on AOI_3_Paris ... done\n"
     ]
    }
   ],
   "source": [
    "# datapaths = ['data/train/AOI_2_Vegas_Train', 'data/train/AOI_3_Paris_Train', 'data/train/AOI_4_Shanghai_Train', 'data/train/AOI_5_Khartoum_Train']\n",
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-12 00:08:16,929 INFO Preproc for training on AOI_5_Khartoum\n",
      "2018-04-12 00:08:16,929 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:08:16,929 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:08:16,929 INFO Generate band stats csv (RGB) ... skip\n",
      "2018-04-12 00:08:16,929 INFO Generate MASK (valtrain) ... skip\n",
      "2018-04-12 00:08:16,929 INFO Generate MASK (valtest) ... skip\n",
      "2018-04-12 00:08:16,929 INFO Generate RGB_STORE (valtrain)\n",
      "2018-04-12 00:08:16,933 INFO prep_rgb_image_store_train for AOI_5_Khartoum\n",
      "2018-04-12 00:08:16,934 INFO Image store file: data/working/images/v5/trn_full_rgb/\n",
      "2018-04-12 00:11:36,933 INFO Generate RGB_STORE (valtest)\n",
      "2018-04-12 00:11:36,947 INFO prep_rgb_image_store_train for AOI_5_Khartoum\n",
      "2018-04-12 00:11:36,949 INFO Image store file: data/working/images/v5/test_full_rgb/\n",
      "2018-04-12 00:12:59,733 INFO Generate RGBMEAN\n",
      "2018-04-12 00:13:25,436 INFO Prepare mean image: data/working/images/v5/AOI_5_Khartoum_immean.h5\n",
      "2018-04-12 00:13:25,475 INFO Preproc for training on AOI_5_Khartoum ... done\n"
     ]
    }
   ],
   "source": [
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-12 00:13:28,875 INFO Preproc for training on AOI_2_Vegas\n",
      "2018-04-12 00:13:28,875 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:13:28,875 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:13:28,875 INFO Generate band stats csv (RGB) ... skip\n",
      "2018-04-12 00:13:28,875 INFO Generate MASK (valtrain) ... skip\n",
      "2018-04-12 00:13:28,875 INFO Generate MASK (valtest) ... skip\n",
      "2018-04-12 00:13:28,875 INFO Generate RGB_STORE (valtrain)\n",
      "2018-04-12 00:13:28,879 INFO prep_rgb_image_store_train for AOI_2_Vegas\n",
      "2018-04-12 00:13:28,882 INFO Image store file: data/working/images/v5/trn_full_rgb/\n",
      "2018-04-12 00:27:09,650 INFO Generate RGB_STORE (valtest)\n",
      "2018-04-12 00:27:09,655 INFO prep_rgb_image_store_train for AOI_2_Vegas\n",
      "2018-04-12 00:27:09,657 INFO Image store file: data/working/images/v5/test_full_rgb/\n",
      "2018-04-12 00:32:47,330 INFO Generate RGBMEAN\n",
      "2018-04-12 00:34:23,289 INFO Prepare mean image: data/working/images/v5/AOI_2_Vegas_immean.h5\n",
      "2018-04-12 00:34:23,969 INFO Preproc for training on AOI_2_Vegas ... done\n",
      "2018-04-12 00:34:30,802 INFO Preproc for training on AOI_4_Shanghai\n",
      "2018-04-12 00:34:30,802 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:34:30,802 INFO Generate IMAGELIST csv ... skip\n",
      "2018-04-12 00:34:30,803 INFO Generate band stats csv (RGB) ... skip\n",
      "2018-04-12 00:34:30,803 INFO Generate MASK (valtrain) ... skip\n",
      "2018-04-12 00:34:30,803 INFO Generate MASK (valtest) ... skip\n",
      "2018-04-12 00:34:30,803 INFO Generate RGB_STORE (valtrain)\n",
      "2018-04-12 00:34:30,814 INFO prep_rgb_image_store_train for AOI_4_Shanghai\n",
      "2018-04-12 00:34:30,824 INFO Image store file: data/working/images/v5/trn_full_rgb/\n",
      "2018-04-12 00:53:04,875 INFO Generate RGB_STORE (valtest)\n",
      "2018-04-12 00:53:04,881 INFO prep_rgb_image_store_train for AOI_4_Shanghai\n",
      "2018-04-12 00:53:04,883 INFO Image store file: data/working/images/v5/test_full_rgb/\n",
      "2018-04-12 01:02:41,461 INFO Generate RGBMEAN\n",
      "2018-04-12 01:05:25,046 INFO Prepare mean image: data/working/images/v5/AOI_4_Shanghai_immean.h5\n",
      "2018-04-12 01:05:25,078 INFO Preproc for training on AOI_4_Shanghai ... done\n"
     ]
    }
   ],
   "source": [
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[0]}\n",
    "# !python code/v5_im-full_rgb.py preproc_train {datapaths[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in datapaths: print(d, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !parallel python code/v5_im-full_rgb.py preproc_train {} ::: data/train/AOI_2_Vegas_Train data/train/AOI_3_Paris_Train data/train/AOI_4_Shanghai_Train data/train/AOI_5_Khartoum_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_path in ['data/train/AOI_2_Vegas_Train', 'data/train/AOI_3_Paris_Train', 'data/train/AOI_4_Shanghai_Train', 'data/train/AOI_5_Khartoum_Train']:\n",
    "#     !python code/v12_im_deeplab.py preproc_train {train_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(area_id, is_test):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    fn_train = FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix) if is_test else FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)\n",
    "    df_train = pd.read_csv(fn_train)\n",
    "    \n",
    "    fn_im = FMT_VALTEST_MASK_STORE.format(prefix) if is_test else FMT_VALTRAIN_MASK_STORE.format(prefix)\n",
    "    y_val = []\n",
    "    with tb.open_file(fn_im, 'r') as f:\n",
    "        for image_id in tqdm.tqdm(df_train.ImageId.tolist(), total=df_train.shape[0]):\n",
    "            fn = '/' + image_id\n",
    "            im = np.array(f.get_node(fn))[None]\n",
    "            y_val.append(im)\n",
    "            \n",
    "    fn_im = FMT_VALTEST_IM_FOLDER if is_test else FMT_VALTRAIN_IM_FOLDER\n",
    "    X_val = []\n",
    "    for image_id in tqdm.tqdm(df_train.ImageId.tolist(), total=df_train.shape[0]):\n",
    "        im = plt.imread(fn_im + image_id + '.png')\n",
    "#             print(im.shape)\n",
    "        X_val.append(im)\n",
    "\n",
    "    X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "    return X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory dataset\n",
    "def get_dataset(datapath):\n",
    "    area_id = directory_name_to_area_id(datapath)\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "    trn_x, trn_y = get_data(area_id, False)\n",
    "#     print(trn_x.shape, trn_y.shape)\n",
    "#     trn_x = np.moveaxis(trn_x, 1, -1).astype('float') # --> [bs, h, w, ch]\n",
    "#     trn_y = np.moveaxis(trn_y, 1, -1).astype('float')\n",
    "\n",
    "    print(trn_x.shape, trn_y.shape)\n",
    "    trn_y = np.broadcast_to(trn_y, [trn_y.shape[0], 3, ORIGINAL_SIZE, ORIGINAL_SIZE])\n",
    "\n",
    "    val_x, val_y = get_data(area_id, True)\n",
    "#     val_x = val_x[:,:3]\n",
    "#     val_x = np.moveaxis(val_x, 1, -1).astype('float')\n",
    "#     val_y = val_y[:,:3]\n",
    "#     val_y = np.moveaxis(val_y, 1, -1).astype('float')\n",
    "    val_y = np.broadcast_to(val_y, [val_y.shape[0], 3, ORIGINAL_SIZE, ORIGINAL_SIZE])\n",
    "               \n",
    "    return (trn_x,trn_y), (val_x,val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapaths = ['data/train/AOI_3_Paris_Train', 'data/train/AOI_2_Vegas_Train', 'data/train/AOI_4_Shanghai_Train', 'data/train/AOI_5_Khartoum_Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:04<00:00, 187.01it/s]\n",
      "100%|██████████| 803/803 [00:02<00:00, 320.84it/s]\n",
      "  3%|▎         | 11/345 [00:00<00:04, 82.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(803, 256, 256, 4) (803, 1, 650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345/345 [00:03<00:00, 96.92it/s]\n",
      "  0%|          | 0/345 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/working/images/v5/trn_full_rgb/AOI_3_Paris_img1669.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-41ebde768c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrn_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-99-2c8ac4301827>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(datapath)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrn_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mORIGINAL_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mORIGINAL_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marea_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#     val_x = val_x[:,:3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     val_x = np.moveaxis(val_x, 1, -1).astype('float')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-a31ea26b60dc>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(area_id, is_test)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_im\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#             print(im.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/twofyw/miniconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/twofyw/miniconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/working/images/v5/trn_full_rgb/AOI_3_Paris_img1669.png'"
     ]
    }
   ],
   "source": [
    "(trn_x,trn_y), (val_x,val_y) = get_dataset(datapaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArraysSingleDataset(BaseDataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x; self.y = y\n",
    "        self.num_groups = len(x)\n",
    "        self.sz = x[0].shape[1]\n",
    "        self.ns = np.array([o.shape[0] for o in x])\n",
    "        self.cum_ns = np.cumsum(self.ns * num_slice)\n",
    "        super().__init__(transform)\n",
    "\n",
    "        \n",
    "    def get_im(self, i, is_y):\n",
    "        idx_file, idx_im = self.get_file_idx(i)\n",
    "        if is_y:\n",
    "            im = self.y[idx_file][idx_im//num_slice]\n",
    "        else:\n",
    "            im = self.x[idx_file][idx_im//num_slice]\n",
    "        slice_pos = idx_im % num_slice\n",
    "        a = np.sqrt(num_slice)\n",
    "        cut_i = slice_pos // a\n",
    "        cut_j = slice_pos % a\n",
    "        stride = (self.sz - sz) // a\n",
    "        cut_x = int(cut_j * stride)\n",
    "        cut_y = int(cut_i * stride)\n",
    "        return im[cut_x:cut_x + sz, cut_y:cut_y + sz]\n",
    "        \n",
    "            \n",
    "    def get_x(self, i): return self.get_im(i, False)\n",
    "    def get_y(self, i): return self.get_im(i, True)\n",
    "        \n",
    "    def get_file_idx(self, i):\n",
    "        idx_file = np.argmax(i + 1 <= self.cum_ns)\n",
    "        if idx_file == 0:\n",
    "            idx_im = i\n",
    "        else:\n",
    "            idx_im = i - self.cum_ns[idx_file - 1]\n",
    "        return idx_file, idx_im\n",
    "    \n",
    "    def get_n(self): return self.cum_ns[-1]\n",
    "    \n",
    "    def get_sz(self): return self.sz\n",
    "        \n",
    "    def get_c(self): return 1\n",
    "    def denorm(self, arr):\n",
    "        \"\"\"Reverse the normalization done to a batch of images.\n",
    "\n",
    "        Arguments:\n",
    "            arr: of shape/size (N,3,sz,sz)\n",
    "        \"\"\"\n",
    "        if type(arr) is not np.ndarray: arr = to_np(arr)\n",
    "        if len(arr.shape)==3: arr = arr[None]\n",
    "#         return np.clip(self.transform.denorm(np.rollaxis(arr,1,4)), 0, 1)\n",
    "        return self.transform.denorm(np.rollaxis(arr,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_base = 8\n",
    "class UpsampleModel():\n",
    "    def __init__(self,model,name='upsample'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        c = list(children(self.model.module))\n",
    "        return [c[:cut_base],\n",
    "               c[cut_base:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred, thresh=0.5):\n",
    "    smooth = 1e-12\n",
    "    ma = torch.max(y_pred)\n",
    "    mi = torch.min(y_pred)\n",
    "    y_pred = to_np((y_pred - mi) / (ma - mi) > thresh)\n",
    "    y_true = np.round(to_np(y_true))\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    sum_ = np.sum(y_true + y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac.mean()\n",
    "\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    smooth = 1e-12\n",
    "    y_true = torch.round(y_true)\n",
    "    y_pred_pos = torch.round(torch.clamp(y_pred, 0, 1))\n",
    "    intersection = torch.sum(y_true * y_pred_pos)\n",
    "    sum_ = torch.sum(y_true + y_pred_pos)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mul_mean_stat(area_id):\n",
    "    prefix = area_id_to_prefix(area_id)\n",
    "\n",
    "    with tb.open_file(FMT_MULMEAN.format(prefix), 'r') as f:\n",
    "        im_mean = np.array(f.get_node('/mulmean'))[:3]\n",
    "    \n",
    "    mean = [np.mean(im_mean[i]) for i in range(3)]\n",
    "    std = [np.std(im_mean[i]) for i in range(3)]\n",
    "    return np.stack([np.array(mean), np.array(std)])\n",
    "\n",
    "def get_md_model(datapaths, device_ids=range(7)):\n",
    "    aug_tfms = transforms_top_down\n",
    "    for o in aug_tfms: o.tfm_y = TfmType.CLASS\n",
    "        \n",
    "    area_ids = [directory_name_to_area_id(datapath) for datapath in datapaths]\n",
    "    stats = np.mean([get_mul_mean_stat(area_id) for area_id in area_ids], axis=0)\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "    \n",
    "    datasets = ImageData.get_ds(ArraysSingleDataset, (trn_x, trn_y), (val_x, val_y), tfms)\n",
    "    md = ImageData('data', datasets, bs, num_workers=int(np.ceil(bs / 3)), classes=None)\n",
    "    denorm = md.trn_ds.denorm\n",
    "\n",
    "    if not Path(MODEL_DIR).exists():\n",
    "        Path(MODEL_DIR).mkdir(parents=True)\n",
    "\n",
    "    net = to_gpu(UNet16(pretrained='vgg'))\n",
    "    net = nn.DataParallel(net, device_ids)\n",
    "    models = UpsampleModel(net)\n",
    "    return md, models, denorm\n",
    "\n",
    "def expanded_loss(pred, target):\n",
    "#     pred = torch.clamp(pred, 0, 1)\n",
    "    return F.binary_cross_entropy_with_logits(pred[:,0], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md, model, denorm = get_md_model([datapaths[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=ConvLearner(md, model)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=expanded_loss\n",
    "learn.metrics=[jaccard_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.module.load_state_dict(torch.load('data/models/unfreezed_1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "learn.freeze_to(1)\n",
    "learn.fit(lr,1,cycle_len=8,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('freezed_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = md.trn_dl.get_batch(range(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    plt.subplot(3, 6, i*2)\n",
    "    plt.imshow(denorm(x[i-1])[0])\n",
    "    plt.subplot(3, 6, i*2-1)\n",
    "    plt.imshow(y[i-1])\n",
    "#     plt.imshow(to_np(learn.model(V(x[i-1][None]))).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    plt.subplot(3, 6, i*2)\n",
    "    plt.imshow(denorm(x[i-1])[0])\n",
    "    plt.subplot(3, 6, i*2-1)\n",
    "#     plt.imshow(y[i-1])\n",
    "    pred = to_np(learn.model(V(x[i-1][None]))).squeeze()\n",
    "#     pred = np.clip(pred, 0, 1)\n",
    "    plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)\n",
    "lrs = np.array([lr/3,lr]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs,5,cycle_len=40,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unfreezed_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unfreezed_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = md.trn_dl.get_batch(np.arange(1, 10) * 4)\n",
    "preds = learn.model(V(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    plt.subplot(3, 6, i*2)\n",
    "    plt.imshow(denorm(x[i-1])[0])\n",
    "    plt.subplot(3, 6, i*2-1)\n",
    "    plt.imshow(y[i-1])\n",
    "#     plt.imshow(to_np(learn.model(V(x[i-1][None]))).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    plt.subplot(3, 6, i*2)\n",
    "    plt.imshow(denorm(x[i-1])[0])\n",
    "    plt.subplot(3, 6, i*2-1)\n",
    "#     plt.imshow(y[i-1])\n",
    "    pred = to_np(learn.model(V(x[i-1][None]))).squeeze()\n",
    "#     pred = np.clip(pred, 0, 1)\n",
    "    plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_np(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_np(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = to_np(learn.model(V(x[1-1][None]))).squeeze()\n",
    "ma = np.max(t)\n",
    "mi = np.min(t)\n",
    "ta = (t - mi) / (ma - mi)\n",
    "print(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(denorm(x[1-1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-12\n",
    "intersection = torch.sum(y_true * y_pred)\n",
    "sum_ = torch.sum(y_true + y_pred)\n",
    "jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "print(jac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ditched experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset(BaseDataset):\n",
    "    def __init__(self, idxs, y, transform, datapaths=datapaths, is_rgb=True):\n",
    "        area_ids = [directory_name_to_area_id(datapath) for datapath in datapaths]\n",
    "        self.prefixes = [area_id_to_prefix(area_id) for area_id in area_ids]\n",
    "        self.is_rgb = is_rgb\n",
    "        self.file_lists = [FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix) for prefix in self.prefixes] +\\\n",
    "            [FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix) for prefix in self.prefixes]\n",
    "        self.x_h5_lists = [FMT_VALTRAIN_MUL_STORE.format(prefix) for prefix in self.prefixes] +\\\n",
    "            [FMT_VALTEST_MUL_STORE.format(prefix) for prefix in self.prefixes]\n",
    "        self.y_h5_lists = [FMT_VALTRAIN_MASK_STORE.format(prefix) for prefix in self.prefixes] +\\\n",
    "            [FMT_VALTEST_MASK_STORE.format(prefix) for prefix in self.prefixes]\n",
    "        self.idxs = idxs # idx of trn or val. 0 ... len-1. Generate by permutation\n",
    "        if transform is not None:\n",
    "            super().__init__(transform)\n",
    "        self.ys = y\n",
    "        \n",
    "        # open all files\n",
    "        self.x_h5_lists_open = [tb.open_file(o) for o in self.x_h5_lists]\n",
    "        self.df_lists = [pd.read_csv(o) for o in self.file_lists]\n",
    "\n",
    "        # choose next h5 after one is exhausted\n",
    "        self.ns = []\n",
    "        for file_list in self.file_lists:\n",
    "            df = pd.read_csv(file_list)\n",
    "            self.ns.append(df.shape[0])\n",
    "        self.ns = np.array(self.ns) # number of pre-crop images\n",
    "        self.cum_ns = np.cumsum(self.ns * num_slice)\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_y(datapaths=datapaths):\n",
    "        dummy_dataset = H5Dataset(None, None, None, datapaths=datapaths)\n",
    "            \n",
    "        y = []\n",
    "        print('Loading masks...')\n",
    "        for idx_file, df_list in enumerate(dummy_dataset.df_lists):\n",
    "            with tb.open_file(dummy_dataset.y_h5_lists[idx_file]) as f:\n",
    "                ys = []\n",
    "                for idx_im in tqdm.tqdm(range(dummy_dataset.ns[idx_file] * num_slice), total=dummy_dataset.ns[idx_file] * num_slice):\n",
    "                    slice_pos = idx_im % num_slice\n",
    "                    im = np.array(f.get_node('/' + df_list.iloc[idx_im // num_slice][0] + '_' + str(slice_pos)))\n",
    "                    im = np.broadcast_to(im[...,None], (256, 256, 3))\n",
    "                    ys.append(im.astype('float'))\n",
    "            y += ys\n",
    "        return np.array(y)\n",
    "\n",
    "        \n",
    "    def get_sz(self): return self.transform.sz\n",
    "    \n",
    "    def get_file_idx(self,i):\n",
    "        idx_file = np.argmax(i + 1 <= self.cum_ns)\n",
    "        if idx_file == 0:\n",
    "            idx_im = i\n",
    "        else:\n",
    "            idx_im = i - self.cum_ns[idx_file - 1]\n",
    "        return idx_file, idx_im\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        idx_file, idx_im = self.get_file_idx(i)\n",
    "        h5_list_open = self.x_h5_lists_open\n",
    "        f = h5_list_open[idx_file]\n",
    "        df_list = self.df_lists[idx_file]\n",
    "        slice_pos = idx_im % num_slice\n",
    "        \n",
    "        im = np.array(f.get_node('/' + df_list.iloc[idx_im // num_slice][0] + '_' + str(slice_pos)))\n",
    "        if self.is_rgb:\n",
    "            # Or other bands\n",
    "            im = im[...,:3]\n",
    "        return im.astype('float')\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        return self.ys[i]\n",
    "        \n",
    "    def get_c(self): return 1\n",
    "        \n",
    "    def get_n(self): return self.idxs.shape[0]\n",
    "\n",
    "#     def resize_imgs(self, targ, new_path):\n",
    "#         dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "#         return self.__class__(self.fnames, self.y, self.transform, dest)\n",
    "\n",
    "    def denorm(self,arr):\n",
    "        \"\"\"Reverse the normalization done to a batch of images.\n",
    "\n",
    "        Arguments:\n",
    "            arr: of shape/size (N,3,sz,sz)\n",
    "        \"\"\"\n",
    "        if type(arr) is not np.ndarray: arr = to_np(arr)\n",
    "        if len(arr.shape)==3: arr = arr[None]\n",
    "        return self.transform.denorm(np.rollaxis(arr,1,4))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_ns(datapaths=datapaths):\n",
    "        return H5Dataset(None, None, None, datapaths=datapaths).cum_ns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rgb scaled\n",
    "# def get_rgb_scaled(datapath):\n",
    "#     area_id = directory_name_to_area_id(datapath)\n",
    "#     prefix = area_id_to_prefix(area_id)\n",
    "    \n",
    "#     X_val = []\n",
    "#     fn_im = FMT_VALTEST_IM_STORE.format(prefix)\n",
    "#     with tb.open_file(fn_im, 'r') as f:\n",
    "#         for idx, image_id in enumerate(df_test.ImageId.tolist()):\n",
    "#             im = np.array(f.get_node('/' + image_id))\n",
    "#             im = np.swapaxes(im, 0, 2)\n",
    "#             im = np.swapaxes(im, 1, 2)\n",
    "#             X_val.append(im)\n",
    "#     X_val = np.array(X_val)\n",
    "\n",
    "#     y_val = []\n",
    "#     fn_mask = FMT_VALTEST_MASK_STORE.format(prefix)\n",
    "#     with tb.open_file(fn_mask, 'r') as f:\n",
    "#         for idx, image_id in enumerate(df_test.ImageId.tolist()):\n",
    "#             mask = np.array(f.get_node('/' + image_id))\n",
    "#             mask = (mask > 0.5).astype(np.uint8)\n",
    "#             y_val.append(mask)\n",
    "#     y_val = np.array(y_val)\n",
    "#     y_val = y_val.reshape((-1, 1, INPUT_SIZE, INPUT_SIZE))\n",
    "#     return X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (trn_x,trn_y), (val_x,val_y) = get_dataset(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_file_list():\n",
    "    df = pd.DataFrame()\n",
    "    # clear file\n",
    "    df.to_csv(FMT_VALTRAIN_IMAGELIST_PATH_ALL)\n",
    "    for datapath in datapaths:\n",
    "        area_id = directory_name_to_area_id(datapath)        \n",
    "        prefix = area_id_to_prefix(area_id)\n",
    "        fn_train = FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)\n",
    "        df_train = pd.read_csv(fn_train)\n",
    "#         fn_a = FMT_VALTRAIN_IMAGELIST_PATH_ALL\n",
    "#         fn_im = FMT_VALTRAIN_MUL_STORE.format(prefix)\n",
    "        fn_test = FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix)\n",
    "        df_test = pd.read_csv(fn_test)\n",
    "        df = df.append(df_train).append(df_test)\n",
    "        \n",
    "    df.to_csv(FMT_VALTRAIN_IMAGELIST_PATH_ALL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def merge_im(rgb=False):\n",
    "    if rgb:\n",
    "        fn_store_w = FMT_VALTRAIN_IM_STORE_ALL\n",
    "    else:\n",
    "        fn_store_w = FMT_VALTRAIN_MUL_STORE_ALL\n",
    "        \n",
    "    with tb.open_file(fn_store_w, 'w') as fw:\n",
    "        for datapath in datapaths:\n",
    "            try:\n",
    "                area_id = directory_name_to_area_id(datapath)        \n",
    "                prefix = area_id_to_prefix(area_id)\n",
    "\n",
    "                # valtrain + valtest\n",
    "                for (fn_store, fn_list) in [(FMT_VALTRAIN_MUL_STORE.format(prefix), FMT_VALTRAIN_IMAGELIST_PATH.format(prefix=prefix)),\n",
    "                                         (FMT_VALTEST_MUL_STORE.format(prefix), FMT_VALTEST_IMAGELIST_PATH.format(prefix=prefix))]:\n",
    "                    df_list = pd.read_csv(fn_list, index_col='ImageId')\n",
    "                    with tb.open_file(fn_store, 'r') as fr:\n",
    "                        for idx, image_id in tqdm.tqdm(enumerate(df_list.index), total=df_list.shape[0]):\n",
    "                            for slice_pos in range(9):\n",
    "                                slice_id = image_id + '_' + str(slice_pos)\n",
    "                                im = np.array(fr.get_node('/' + slice_id))\n",
    "                                im = np.swapaxes(im, 0, 2)\n",
    "                                im = np.swapaxes(im, 1, 2)\n",
    "                                if rgb:\n",
    "                                    im = im[:3,...]\n",
    "                                atom = tb.Atom.from_dtype(im.dtype)\n",
    "                                filters = tb.Filters(complib='blosc', complevel=9)\n",
    "                                ds = fw.create_carray(fw.root, slice_id, atom, im.shape,\n",
    "                                                     filters=filters)\n",
    "                                ds[:] = im\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                print(datapath, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_file_list()\n",
    "# df = pd.read_csv(FMT_VALTRAIN_IMAGELIST_PATH_ALL)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_im(True)\n",
    "# merge_im(False) # Too big"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
